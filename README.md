# Ollama Local Chat

Приложение для общения с локальными LLM моделями через Ollama API.

## Особенности

- Подключение к локально запущенному Ollama на порту 11434
- Выбор различных моделей (Phi-3, TinyLlama, и других)
- Поддержка загрузки файлов и вложений
- История чата с возможностью сохранения и восстановления

## Хранение истории чата

История чата сохраняется автоматически с помощью нескольких механизмов:

1. **IndexedDB**: Основной механизм хранения с большой емкостью
2. **LocalStorage**: Используется как резервное копирование
3. **Экспорт файлов**: Возможность создания резервных копий

Все данные хранятся локально на вашем устройстве и никуда не отправляются.

### Управление историей чата

Приложение предлагает несколько опций для управления историей чата:

1. **Несколько сессий**: Создание и управление несколькими беседами
2. **Автосохранение**: Беседы автоматически сохраняются
3. **Резервное копирование**:
   - **Экспорт текущего чата**: Сохранение текущей беседы в JSON-файл
   - **Экспорт всех чатов**: Полное резервное копирование
   - **Импорт чатов**: Восстановление из резервной копии
4. **Организация чатов**: Удобное переключение между беседами

### Вложения файлов

1. **Поддерживаемые типы файлов**: Изображения, PDF, текстовые файлы и документы
2. **Предпросмотр**: Изображения показывают превью в чате
3. **Хранилище**: Файлы хранятся локально в IndexedDB браузера
4. **Открытие**: Файлы можно открыть в новых вкладках или скачать
